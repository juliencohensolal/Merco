{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width: 90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA, TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, RidgeCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor, DMatrix\n",
    "from pylightgbm.models import GBMRegressor\n",
    "\n",
    "# Visualization options\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width: 90% !important; }</style>\"))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Global variables\n",
    "SEED = 420\n",
    "N_JOBS = 18\n",
    "FOLDS = 10\n",
    "os.environ[\"LIGHTGBM_EXEC\"] = \"C:/Users/Julien/LightGBM/lightgbm.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Utilities functions\n",
    "def encodeLetters(charcode) : \n",
    "    code = 0\n",
    "    length = len(str(charcode))\n",
    "    for i in range(length) :\n",
    "        # example : AC = 1 * 26 ^ 1 + 3 * 26 ^ 0\n",
    "        code += (ord(str(charcode)[i]) - ord(\"a\") + 1) * (26 ** (length - i - 1)) - 1\n",
    "    return(code)\n",
    "\n",
    "def findDuplicateVars(df) :\n",
    "    cols = df.columns\n",
    "    removed_cols = []\n",
    "    for i in range(len(cols) - 1) :\n",
    "        v = df[cols[i]].values\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            if np.array_equal(v, df[cols[j]].values) :\n",
    "                #print(\"Dups : \" + str(cols[i]) + \" and \" + str(cols[j]))\n",
    "                removed_cols.append(cols[j])\n",
    "    return(removed_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def config_dataset(train, test, conf, conf_name, probe_df, verbose = False) :\n",
    "    print(\"***** CONFIG : \" + conf_name + \"\\n\" + str(conf))\n",
    "    \n",
    "    ##################################\n",
    "    if (conf[\"probe\"] == \"true\") :\n",
    "        # Use probed public LB y values in training set\n",
    "        train = pd.concat([train, probe_df], axis = 0)\n",
    "        train.reset_index(drop = True, inplace = True)\n",
    "        test = test.reindex_axis(sorted(test.columns), axis = 1)\n",
    "\n",
    "    ##################################\n",
    "    if (conf[\"log_target\"] >= 0) :\n",
    "        # Log transform target\n",
    "        train.y = np.log(train.y + conf[\"log_target\"])\n",
    "\n",
    "    ##################################\n",
    "    if (conf[\"mean_x\"] > 0) :\n",
    "        # Add mean of y for each Xy\n",
    "        vars = [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]\n",
    "        for i in range(conf[\"mean_x\"]) :\n",
    "            col = vars[i]\n",
    "            y_x = train[[col, \"y\"]].groupby([col], as_index = False).mean()\n",
    "            y_x.columns = [col, \"y_\" + col]\n",
    "            \n",
    "            train = pd.merge(train, y_x, on = col, how = \"outer\")\n",
    "            train.sort_values([\"ID\"], ascending = True, inplace = True)\n",
    "            train.reset_index(drop = True, inplace = True)\n",
    "            \n",
    "            test = pd.merge(test, y_x, on = col, how = \"left\")\n",
    "            test[\"y_\" + col].fillna(test[\"y_\" + col].dropna().mean(), inplace = True)   # fillna with groups means instead?  \n",
    "            \n",
    "            test.sort_values([\"ID\"], ascending = True, inplace = True)\n",
    "            test.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "    ##################################\n",
    "    if (conf[\"constant_vars\"] == \"without\") :\n",
    "        # Remove variables constant in the train set\n",
    "        constant_vars = []\n",
    "        for col in train.drop(\"y\", axis = 1).columns:\n",
    "            if(train[col].nunique() == 1):\n",
    "                constant_vars.append(col)\n",
    "        if (verbose) :\n",
    "            print(\"Removing constant variables : \" + str(constant_vars))            \n",
    "        train.drop(constant_vars, axis = 1, inplace = True)\n",
    "        test.drop(constant_vars, axis = 1, inplace = True)\n",
    "        \n",
    "    ##################################\n",
    "    if (conf[\"dupli_vars\"] == \"remove_train\") :\n",
    "        # Remove variables duplicate in train\n",
    "        old_nb_vars = train.shape[1]\n",
    "        removed_vars = findDuplicateVars(train)\n",
    "        removed_vars = list(set(removed_vars))\n",
    "        train.drop(removed_vars, axis = 1, inplace = True)\n",
    "        test.drop(removed_vars, axis = 1, inplace = True)\n",
    "        if (verbose) :\n",
    "            print(\"Removed \" + str(old_nb_vars - train.shape[1]) + \" duplicate variables\")\n",
    "            print(sorted(removed_vars))\n",
    "    elif (conf[\"dupli_vars\"] == \"remove_train+test\") :\n",
    "        # Remove variables duplicate in train+test\n",
    "        old_nb_vars = train.shape[1]\n",
    "        alldata = pd.concat([train.drop(\"y\", axis = 1), test], axis = 0)\n",
    "        removed_vars = findDuplicateVars(alldata)\n",
    "        removed_vars = list(set(removed_vars))\n",
    "        train.drop(removed_vars, axis = 1, inplace = True)\n",
    "        test.drop(removed_vars, axis = 1, inplace = True)\n",
    "        if (verbose) :\n",
    "            print(\"Removed \" + str(old_nb_vars - train.shape[1]) + \" duplicate variables\")\n",
    "            print(sorted(removed_vars))\n",
    "        \n",
    "    ##################################\n",
    "    if (conf[\"dupli_rows\"] == \"mean\") :\n",
    "        # Remove row duplicates with mean value\n",
    "        cols_to_groupby = [k for k in train.columns if k not in [\"ID\", \"y\"]] \n",
    "        cols_to_apply = cols_to_groupby + [\"y\"]\n",
    "        train = train[cols_to_apply].groupby(cols_to_groupby, as_index = False).mean()\n",
    "        train.columns = cols_to_apply\n",
    "        y = pd.DataFrame({\"y\": train.y})\n",
    "        test.drop([\"ID\"], axis = 1, inplace = True)\n",
    "    elif (conf[\"dupli_rows\"] == \"median\") :\n",
    "        # Remove row duplicates with median value\n",
    "        cols_to_groupby = [k for k in train.columns if k not in [\"ID\", \"y\"]] \n",
    "        cols_to_apply = cols_to_groupby + [\"y\"]\n",
    "        train = train[cols_to_apply].groupby(cols_to_groupby, as_index = False).median()\n",
    "        train.columns = cols_to_apply\n",
    "        y = pd.DataFrame({\"y\": train.y})\n",
    "        test.drop([\"ID\"], axis = 1, inplace = True)\n",
    "    elif (conf[\"dupli_rows\"] == \"min\") :\n",
    "        # Remove row duplicates with median value\n",
    "        cols_to_groupby = [k for k in train.columns if k not in [\"ID\", \"y\"]] \n",
    "        cols_to_apply = cols_to_groupby + [\"y\"]\n",
    "        train = train[cols_to_apply].groupby(cols_to_groupby, as_index = False).min()\n",
    "        train.columns = cols_to_apply\n",
    "        y = pd.DataFrame({\"y\": train.y})\n",
    "        test.drop([\"ID\"], axis = 1, inplace = True)\n",
    "        \n",
    "    ##################################\n",
    "    if (conf[\"encode_cats\"] == \"LE\") :\n",
    "        # Encode cat variables with LabelEncoder\n",
    "        for c in train.drop(\"y\", axis = 1).columns:\n",
    "            if train[c].dtype == \"object\" :\n",
    "                lbl = LabelEncoder() \n",
    "                lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "                train[c] = lbl.transform(list(train[c].values))\n",
    "                test[c] = lbl.transform(list(test[c].values))\n",
    "    elif (conf[\"encode_cats\"] == \"LE+\") :\n",
    "        # Encode cat variables with a custom LabelEncoder using the right letter order (i.e. \"aa\" is 26, not 2)\n",
    "        for c in train.drop(\"y\", axis = 1).columns:\n",
    "            if train[c].dtype == \"object\" :\n",
    "                lbl = LabelEncoder() \n",
    "                lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "                train[c] = train[c].apply(encodeLetters)\n",
    "                test[c] = test[c].apply(encodeLetters)\n",
    "    elif (conf[\"encode_cats\"] == \"dummies\") :\n",
    "        # Encode cat variables as dummy variables\n",
    "        temp_y = train.y\n",
    "        alldata = pd.concat([train.drop(\"y\", axis = 1), test], axis = 0)\n",
    "        alldata = pd.get_dummies(alldata).astype(int)\n",
    "        train = alldata.iloc[:train.shape[0], :]\n",
    "        test = alldata.iloc[train.shape[0]: , :]\n",
    "        train[\"y\"] = temp_y\n",
    "    elif (conf[\"encode_cats\"] == \"drop\") :\n",
    "        # Drop cat variables\n",
    "        binary_vars_train = list(set(train.columns.drop([\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])))\n",
    "        binary_vars_test = list(set(test.columns.drop([\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])))\n",
    "        train = train[binary_vars_train]\n",
    "        test = test[binary_vars_test]     \n",
    "        \n",
    "    ##################################\n",
    "    if (conf[\"binary_counts\"] == \"with\") :\n",
    "        # Add columns with count of 1s for each binary col\n",
    "        if (\"X0\" in train.columns) :\n",
    "            if (conf[\"dupli_vars\"] is False) :\n",
    "                binary_vars = list(set(train.columns.drop([\"ID\", \"y\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])))\n",
    "            else :\n",
    "                binary_vars = list(set(train.columns.drop([\"y\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])))\n",
    "        else : \n",
    "            if (conf[\"dupli_vars\"] is False) :\n",
    "                binary_vars = list(set(train.columns.drop([\"ID\", \"y\"])))\n",
    "            else :\n",
    "                binary_vars = list(set(train.columns.drop([\"y\"])))\n",
    "        train[\"bin_ones\"] = (train[binary_vars] == 1).astype(int).sum(axis = 1)\n",
    "        test[\"bin_ones\"] = (test[binary_vars] == 1).astype(int).sum(axis = 1)         \n",
    "        \n",
    "    ##################################\n",
    "    vars_to_reduce = list(set(train.columns.drop([\"y\"])))\n",
    "    \n",
    "    if (conf[\"pca\"] > 0) :\n",
    "        pca = PCA(n_components = conf[\"pca\"], random_state = SEED)\n",
    "        pca_train = pca.fit_transform(train[vars_to_reduce])\n",
    "        pca_test = pca.transform(test)\n",
    "    if (conf[\"ica\"] > 0) :\n",
    "        ica = FastICA(n_components = conf[\"ica\"], random_state = SEED)\n",
    "        ica_train = ica.fit_transform(train[vars_to_reduce])\n",
    "        ica_test = ica.transform(test)\n",
    "    if (conf[\"tsvd\"] > 0) :\n",
    "        tsvd = TruncatedSVD(n_components = conf[\"tsvd\"], random_state = SEED)\n",
    "        tsvd_train = tsvd.fit_transform(train[vars_to_reduce])\n",
    "        tsvd_test = tsvd.transform(test)\n",
    "    if (conf[\"grp\"] > 0) :\n",
    "        grp = GaussianRandomProjection(n_components = conf[\"grp\"], random_state = SEED)\n",
    "        grp_train = grp.fit_transform(train[vars_to_reduce])\n",
    "        grp_test = grp.transform(test)\n",
    "    if (conf[\"srp\"] > 0) :\n",
    "        srp = SparseRandomProjection(n_components = conf[\"srp\"], random_state = SEED)\n",
    "        srp_train = srp.fit_transform(train[vars_to_reduce])\n",
    "        srp_test = srp.transform(test)\n",
    "\n",
    "    if (conf[\"pca\"] > 0) :\n",
    "        for i in range(1, conf[\"pca\"] + 1) :\n",
    "            train[\"pca_\" + str(i)] = pca_train[:, i - 1]\n",
    "            test[\"pca_\" + str(i)] = pca_test[:, i - 1]\n",
    "    if (conf[\"ica\"] > 0) :\n",
    "        for i in range(1, conf[\"ica\"] + 1) :\n",
    "            train[\"ica_\" + str(i)] = ica_train[:, i - 1]\n",
    "            test[\"ica_\" + str(i)] = ica_test[:, i - 1]\n",
    "    if (conf[\"tsvd\"] > 0) :\n",
    "        for i in range(1, conf[\"tsvd\"] + 1) :\n",
    "            train[\"tsvd_\" + str(i)] = tsvd_train[:, i - 1]\n",
    "            test[\"tsvd_\" + str(i)] = tsvd_test[:, i - 1]\n",
    "    if (conf[\"grp\"] > 0) :\n",
    "        for i in range(1, conf[\"grp\"] + 1) :\n",
    "            train[\"grp_\" + str(i)] = grp_train[:, i - 1]\n",
    "            test[\"grp_\" + str(i)] = grp_test[:, i - 1]\n",
    "    if (conf[\"srp\"] > 0) :\n",
    "        for i in range(1, conf[\"srp\"] + 1) :\n",
    "            train[\"srp_\" + str(i)] = srp_train[:, i - 1]\n",
    "            test[\"srp_\" + str(i)] = srp_test[:, i - 1]\n",
    "\n",
    "    train.sort_index(axis = 1, inplace = True)\n",
    "    test.sort_index(axis = 1, inplace = True)\n",
    "    y = pd.DataFrame({\"y\": train.y})\n",
    "    #print(train.shape)\n",
    "    #display(train.head(3))\n",
    "    #display(test.head(3))\n",
    "    return (train, test, y)\n",
    "\n",
    "# TODO : add column counting number of duplicate rows for each row\n",
    "# TODO : post-process preds to get away from the 4 groups and closer to the real y distrib\n",
    "# TODO : add best features from xgb fi\n",
    "# Instead of replacing by y_mean new levels in test set, replace by median of good \"group\" (see https://www.kaggle.com/robertoruiz/the-only-ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cv_score(X_train, X_train_y, model, model_name, conf, conf_name) :\n",
    "    oof_preds = pd.DataFrame()\n",
    "    oof_targets = pd.DataFrame()\n",
    "    kf = KFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        #print(\"FOLD \" + str(i + 1))\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = X_train_y.iloc[train_index], X_train_y.iloc[test_index]\n",
    "\n",
    "        # Fit and predict\n",
    "        model.fit(X_train_fold, y_train_fold.y)\n",
    "        preds_X_test_fold = model.predict(X_test_fold)\n",
    "        \n",
    "        # Assemble OOF predictions and targets\n",
    "        oof_preds = pd.concat([pd.Series(oof_preds), pd.Series(preds_X_test_fold)], axis = 0)\n",
    "        oof_targets = pd.concat([pd.Series(oof_targets), pd.Series(y_test_fold.y)], axis = 0)\n",
    "        \n",
    "    if (conf[\"log_target\"] >= 0) :\n",
    "        # Transform preds back if needed\n",
    "        oof_preds = np.exp(oof_preds) - conf[\"log_target\"]\n",
    "        oof_targets = np.exp(oof_targets) - conf[\"log_target\"]\n",
    "\n",
    "    # Compute error on concatenated OOF predictions\n",
    "    #print(\"Nb of NA in oof_preds : \" + str(oof_preds.isnull().values.sum()))\n",
    "    #print(\"Nb of NA in oof_targets : \" + str(oof_targets.isnull().values.sum()))\n",
    "    #display(oof_targets.head())\n",
    "    #display(oof_preds.head())\n",
    "    cv_score = r2_score(oof_targets, oof_preds)\n",
    "    print(\"Global OOF r2_score : \" + str(cv_score))\n",
    "\n",
    "    if isinstance(model, (RidgeCV, KNeighborsRegressor)) :\n",
    "        # Handle format problems\n",
    "        oof_preds = pd.DataFrame(oof_preds).iloc[:, 0].values            \n",
    "    \n",
    "    # Save OOF preds\n",
    "    file_name = \"oof_preds/temp/\" + model_name + \"_\" + conf_name + \"_preds_OOF.csv\"\n",
    "    pd.DataFrame({\"y\": oof_preds}).to_csv(file_name, index = False)\n",
    "    file_name = \"oof_targets/temp/\" + model_name + \"_\" + conf_name + \"_targets_OOF.csv\"\n",
    "    pd.DataFrame({\"y\": oof_targets}).to_csv(file_name, index = False)\n",
    "                    \n",
    "    return(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def replace_probed_y(row):\n",
    "    if (np.isnan(row[\"y_y\"])) :\n",
    "        return (row[\"y_x\"])\n",
    "    else :\n",
    "        return (row[\"y_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_generator(models, data_configs, init_train, init_test, probe_df) :\n",
    "    # Clear predictions directories\n",
    "    list(map(os.unlink, (os.path.join(\"oof_preds/temp/\",f) for f in os.listdir(\"oof_preds/temp/\"))))\n",
    "    list(map(os.unlink, (os.path.join(\"oof_targets/temp/\",f) for f in os.listdir(\"oof_targets/temp/\"))))\n",
    "    list(map(os.unlink, (os.path.join(\"preds/temp/\",f) for f in os.listdir(\"preds/temp/\"))))\n",
    "    \n",
    "    # Iterate on each available model definition\n",
    "    results = pd.DataFrame()\n",
    "    for model_name, model  in models.items() :\n",
    "        # Iterate on each data configuration :\n",
    "        for conf_name, conf in data_configs.items() :\n",
    "            print(\"***** MODEL : \" + model_name + \" ***************\")\n",
    "            start = time.time()\n",
    "\n",
    "            # Configure dataset\n",
    "            train = init_train.copy()\n",
    "            test = init_test.copy()\n",
    "            train, test, y = config_dataset(train, test, conf, conf_name, probe_df)\n",
    "            train.drop(\"y\", axis = 1, inplace = True)\n",
    "\n",
    "            # Get CV score\n",
    "            cv_score = get_cv_score(train, y, model, model_name, conf, conf_name)\n",
    "\n",
    "            # Fit, predict\n",
    "            model.fit(train, y)\n",
    "            preds_test = model.predict(test)\n",
    "\n",
    "            # Handle format problems before saving\n",
    "            if isinstance(model, (RidgeCV, KNeighborsRegressor)) :\n",
    "                preds_test = pd.DataFrame(preds_test).iloc[:, 0].values            \n",
    "            if (conf[\"log_target\"] >= 0) :\n",
    "                # Transform preds back if needed\n",
    "                preds_test = np.exp(preds_test) - conf[\"log_target\"]\n",
    "                        \n",
    "            # Modify probed values\n",
    "            save_df = pd.DataFrame({\"ID\": init_test.ID.values, \"y\": preds_test})\n",
    "            save_df = pd.merge(save_df, probe_df[[\"ID\", \"y\"]], how = \"left\", on = \"ID\")\n",
    "            save_df[\"y\"] = save_df.apply(replace_probed_y, axis = 1)\n",
    "            save_df.drop([\"y_x\", \"y_y\"], axis = 1, inplace = True)\n",
    "            \n",
    "            # Save preds\n",
    "            file_name = \"preds/temp/\" + model_name + \"_\" + conf_name + \"_preds_test.csv\"\n",
    "            save_df.to_csv(file_name, index = False)\n",
    "\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Elapsed : \" + str(elapsed))\n",
    "\n",
    "            # Store results\n",
    "            cur_result = pd.DataFrame(columns = [\"name\", \"conf\", \"cv\", \"time\"])\n",
    "            cur_result.loc[0] = [model_name, conf_name, cv_score, elapsed] \n",
    "            results = pd.concat([results, cur_result], axis = 0)\n",
    "\n",
    "    return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "#    \"la\" : LassoCV(eps = 0.0001, \n",
    "#                   n_alphas = 100, \n",
    "#                   max_iter = 10000, \n",
    "#                   tol = 0.0001,                     \n",
    "#                   normalize = True, \n",
    "#                   precompute = True, \n",
    "#                   random_state = SEED,\n",
    "#                   n_jobs = N_JOBS),\n",
    "#    \"ll\" : LassoLarsCV(max_n_alphas = 1000, \n",
    "#                       max_iter = 10000,\n",
    "#                       normalize = True, \n",
    "#                       precompute = True, \n",
    "#                       n_jobs = N_JOBS),\n",
    "#    \"ri\" : RidgeCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6]),\n",
    "#    \"rf\" : RandomForestRegressor(n_estimators = 200,\n",
    "#                                 criterion = \"mse\", \n",
    "#                                 max_features = 0.75,\n",
    "#                                 max_depth = 8,\n",
    "#                                 min_samples_split = 5,\n",
    "#                                 min_samples_leaf = 2, \n",
    "#                                 bootstrap = True, \n",
    "#                                 n_jobs = N_JOBS, \n",
    "#                                 random_state = SEED),\n",
    "#    \"zr\" : RandomForestRegressor(n_estimators = 200,\n",
    "#                                 criterion = \"mse\", \n",
    "#                                 max_features = 0.9,\n",
    "#                                 max_depth = 5,\n",
    "#                                 min_samples_split = 20,\n",
    "#                                 min_samples_leaf = 5, \n",
    "#                                 bootstrap = True, \n",
    "#                                 n_jobs = N_JOBS, \n",
    "#                                 random_state = SEED),\n",
    "#    \"et\" : ExtraTreesRegressor(n_estimators = 200,\n",
    "#                               criterion = \"mse\", \n",
    "#                               max_features = 0.75,\n",
    "#                               max_depth = 8,\n",
    "#                               min_samples_split = 5,\n",
    "#                               min_samples_leaf = 2, \n",
    "#                               bootstrap = True, \n",
    "#                               n_jobs = N_JOBS, \n",
    "#                               random_state = SEED), \n",
    "#    \"ze\" : ExtraTreesRegressor(n_estimators = 200,\n",
    "#                               criterion = \"mse\", \n",
    "#                               max_features = 0.9,\n",
    "#                               max_depth = 5,\n",
    "#                               min_samples_split = 20,\n",
    "#                               min_samples_leaf = 5, \n",
    "#                               bootstrap = True, \n",
    "#                               n_jobs = N_JOBS, \n",
    "#                               random_state = SEED), \n",
    "#    \"kn\" : KNeighborsRegressor(n_neighbors = 100, \n",
    "#                               weights = \"distance\", \n",
    "#                               p = 2, \n",
    "#                               n_jobs = N_JOBS), \n",
    "#    \"gb\" : GradientBoostingRegressor(loss = \"ls\", \n",
    "#                                     learning_rate = 0.01, \n",
    "#                                     n_estimators = 200, \n",
    "#                                     max_depth = 8,\n",
    "#                                     criterion = \"friedman_mse\",\n",
    "#                                     min_samples_split = 5,\n",
    "#                                     min_samples_leaf = 2,\n",
    "#                                     subsample = 0.75,\n",
    "#                                     max_features = 0.75, \n",
    "#                                     random_state = SEED),\n",
    "#    \"xg\" : XGBRegressor(objective = \"reg:linear\", \n",
    "#                        learning_rate = 0.01, \n",
    "#                        n_estimators = 1000, \n",
    "#                        max_depth = 8,\n",
    "#                        min_child_weight = 2, \n",
    "#                        subsample = 0.75, \n",
    "#                        colsample_bytree = 0.75, \n",
    "#                        colsample_bylevel = 0.75, \n",
    "#                        nthread = N_JOBS,\n",
    "#                        seed = SEED),\n",
    "#    \"zx\" : XGBRegressor(objective = \"reg:linear\", \n",
    "#                        learning_rate = 0.01, \n",
    "#                        n_estimators = 800, \n",
    "#                        max_depth = 4,\n",
    "#                        min_child_weight = 8, \n",
    "#                        subsample = 0.9, \n",
    "#                        colsample_bytree = 0.7, \n",
    "#                        colsample_bylevel = 0.9, \n",
    "#                        nthread = N_JOBS,\n",
    "#                        seed = SEED),\n",
    "     \"zl\" : GBMRegressor(tree_learner = \"serial\", \n",
    "                         application = \"regression\", \n",
    "                         metric = \"l2\",\n",
    "                         learning_rate = 0.01,\n",
    "                         num_iterations = 1075,\n",
    "                         min_data_in_leaf = 15,\n",
    "                         feature_fraction = 0.2,\n",
    "                         feature_fraction_seed = SEED,\n",
    "                         bagging_fraction = 1.0,\n",
    "                         bagging_freq = 50,\n",
    "                         bagging_seed = SEED,\n",
    "                         max_depth = 3,\n",
    "                         verbose = False,\n",
    "                         num_threads = N_JOBS),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dc1 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc2 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc3 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "dc4 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "dc5 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc6 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc7 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "dc8 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : \"median\",\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "dc9 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc10 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc11 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "dc12 = {\n",
    "    \"probe\" : \"true\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "dc13 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc14 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 10,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 10,\n",
    "    \"grp\" : 10,\n",
    "    \"srp\" : 6,\n",
    "}\n",
    "\n",
    "dc15 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"LE\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "dc16 = {\n",
    "    \"probe\" : \"false\",\n",
    "    \"log_target\" : 10,\n",
    "    \"encode_cats\" : \"dummies\",\n",
    "    \"constant_vars\" : \"without\",\n",
    "    \"dupli_vars\" : \"without\",\n",
    "    \"binary_counts\" : \"with\",\n",
    "    \"mean_x\" : 8,\n",
    "    \"dupli_rows\" : False,\n",
    "    \"pca\" : 0,\n",
    "    \"ica\" : 0,\n",
    "    \"tsvd\" : 0,\n",
    "    \"grp\" : 0,\n",
    "    \"srp\" : 0,\n",
    "}\n",
    "\n",
    "\n",
    "data_configs = {\n",
    "    \"dc1\" : dc1,\n",
    "    \"dc2\" : dc2,\n",
    "    \"dc3\" : dc3,\n",
    "    \"dc4\" : dc4,\n",
    "    \"dc5\" : dc5,\n",
    "    \"dc6\" : dc6,\n",
    "    \"dc7\" : dc7,\n",
    "    \"dc8\" : dc8,\n",
    "    \"dc9\" : dc9,\n",
    "    \"dc10\" : dc10,\n",
    "    \"dc11\" : dc11,\n",
    "    \"dc12\" : dc12,\n",
    "    \"dc13\" : dc13,\n",
    "    \"dc14\" : dc14,\n",
    "    \"dc15\" : dc15,\n",
    "    \"dc16\" : dc16,\n",
    "}\n",
    "\n",
    "data_configs_lx = {\n",
    "    \"dc5\" : dc5,\n",
    "    \"dc6\" : dc6,\n",
    "    \"dc7\" : dc7,\n",
    "    \"dc8\" : dc8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Script</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>X24</th>\n",
       "      <th>X26</th>\n",
       "      <th>X27</th>\n",
       "      <th>X28</th>\n",
       "      <th>X29</th>\n",
       "      <th>X30</th>\n",
       "      <th>X31</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>X41</th>\n",
       "      <th>X42</th>\n",
       "      <th>X43</th>\n",
       "      <th>X44</th>\n",
       "      <th>X45</th>\n",
       "      <th>X46</th>\n",
       "      <th>X47</th>\n",
       "      <th>X48</th>\n",
       "      <th>X49</th>\n",
       "      <th>X50</th>\n",
       "      <th>X51</th>\n",
       "      <th>X52</th>\n",
       "      <th>X53</th>\n",
       "      <th>X54</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>X65</th>\n",
       "      <th>X66</th>\n",
       "      <th>X67</th>\n",
       "      <th>X68</th>\n",
       "      <th>X69</th>\n",
       "      <th>X70</th>\n",
       "      <th>X71</th>\n",
       "      <th>X73</th>\n",
       "      <th>X74</th>\n",
       "      <th>X75</th>\n",
       "      <th>X76</th>\n",
       "      <th>X77</th>\n",
       "      <th>X78</th>\n",
       "      <th>X79</th>\n",
       "      <th>X80</th>\n",
       "      <th>X81</th>\n",
       "      <th>X82</th>\n",
       "      <th>X83</th>\n",
       "      <th>X84</th>\n",
       "      <th>X85</th>\n",
       "      <th>X86</th>\n",
       "      <th>X87</th>\n",
       "      <th>X88</th>\n",
       "      <th>X89</th>\n",
       "      <th>X90</th>\n",
       "      <th>X91</th>\n",
       "      <th>X92</th>\n",
       "      <th>X93</th>\n",
       "      <th>X94</th>\n",
       "      <th>X95</th>\n",
       "      <th>X96</th>\n",
       "      <th>X97</th>\n",
       "      <th>X98</th>\n",
       "      <th>X99</th>\n",
       "      <th>X100</th>\n",
       "      <th>X101</th>\n",
       "      <th>X102</th>\n",
       "      <th>X103</th>\n",
       "      <th>X104</th>\n",
       "      <th>X105</th>\n",
       "      <th>X106</th>\n",
       "      <th>X107</th>\n",
       "      <th>X108</th>\n",
       "      <th>X109</th>\n",
       "      <th>X110</th>\n",
       "      <th>X111</th>\n",
       "      <th>X112</th>\n",
       "      <th>X113</th>\n",
       "      <th>X114</th>\n",
       "      <th>X115</th>\n",
       "      <th>X116</th>\n",
       "      <th>X117</th>\n",
       "      <th>X118</th>\n",
       "      <th>X119</th>\n",
       "      <th>X120</th>\n",
       "      <th>X122</th>\n",
       "      <th>X123</th>\n",
       "      <th>X124</th>\n",
       "      <th>X125</th>\n",
       "      <th>X126</th>\n",
       "      <th>X127</th>\n",
       "      <th>X128</th>\n",
       "      <th>X129</th>\n",
       "      <th>X130</th>\n",
       "      <th>X131</th>\n",
       "      <th>X132</th>\n",
       "      <th>X133</th>\n",
       "      <th>X134</th>\n",
       "      <th>X135</th>\n",
       "      <th>X136</th>\n",
       "      <th>X137</th>\n",
       "      <th>X138</th>\n",
       "      <th>X139</th>\n",
       "      <th>X140</th>\n",
       "      <th>X141</th>\n",
       "      <th>X142</th>\n",
       "      <th>X143</th>\n",
       "      <th>X144</th>\n",
       "      <th>X145</th>\n",
       "      <th>X146</th>\n",
       "      <th>X147</th>\n",
       "      <th>X148</th>\n",
       "      <th>X150</th>\n",
       "      <th>X151</th>\n",
       "      <th>X152</th>\n",
       "      <th>X153</th>\n",
       "      <th>X154</th>\n",
       "      <th>X155</th>\n",
       "      <th>X156</th>\n",
       "      <th>X157</th>\n",
       "      <th>X158</th>\n",
       "      <th>X159</th>\n",
       "      <th>X160</th>\n",
       "      <th>X161</th>\n",
       "      <th>X162</th>\n",
       "      <th>X163</th>\n",
       "      <th>X164</th>\n",
       "      <th>X165</th>\n",
       "      <th>X166</th>\n",
       "      <th>X167</th>\n",
       "      <th>X168</th>\n",
       "      <th>X169</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>X179</th>\n",
       "      <th>X180</th>\n",
       "      <th>X181</th>\n",
       "      <th>X182</th>\n",
       "      <th>X183</th>\n",
       "      <th>X184</th>\n",
       "      <th>X185</th>\n",
       "      <th>X186</th>\n",
       "      <th>X187</th>\n",
       "      <th>X189</th>\n",
       "      <th>X190</th>\n",
       "      <th>X191</th>\n",
       "      <th>X192</th>\n",
       "      <th>X194</th>\n",
       "      <th>X195</th>\n",
       "      <th>X196</th>\n",
       "      <th>X197</th>\n",
       "      <th>X198</th>\n",
       "      <th>X199</th>\n",
       "      <th>X200</th>\n",
       "      <th>X201</th>\n",
       "      <th>X202</th>\n",
       "      <th>X203</th>\n",
       "      <th>X204</th>\n",
       "      <th>X205</th>\n",
       "      <th>X206</th>\n",
       "      <th>X207</th>\n",
       "      <th>X208</th>\n",
       "      <th>X209</th>\n",
       "      <th>X210</th>\n",
       "      <th>X211</th>\n",
       "      <th>X212</th>\n",
       "      <th>X213</th>\n",
       "      <th>X214</th>\n",
       "      <th>X215</th>\n",
       "      <th>X216</th>\n",
       "      <th>X217</th>\n",
       "      <th>X218</th>\n",
       "      <th>X219</th>\n",
       "      <th>X220</th>\n",
       "      <th>X221</th>\n",
       "      <th>X222</th>\n",
       "      <th>X223</th>\n",
       "      <th>X224</th>\n",
       "      <th>X225</th>\n",
       "      <th>X226</th>\n",
       "      <th>X227</th>\n",
       "      <th>X228</th>\n",
       "      <th>X229</th>\n",
       "      <th>X230</th>\n",
       "      <th>X231</th>\n",
       "      <th>X232</th>\n",
       "      <th>X233</th>\n",
       "      <th>X234</th>\n",
       "      <th>X235</th>\n",
       "      <th>X236</th>\n",
       "      <th>X237</th>\n",
       "      <th>X238</th>\n",
       "      <th>X239</th>\n",
       "      <th>X240</th>\n",
       "      <th>X241</th>\n",
       "      <th>X242</th>\n",
       "      <th>X243</th>\n",
       "      <th>X244</th>\n",
       "      <th>X245</th>\n",
       "      <th>X246</th>\n",
       "      <th>X247</th>\n",
       "      <th>X248</th>\n",
       "      <th>X249</th>\n",
       "      <th>X250</th>\n",
       "      <th>X251</th>\n",
       "      <th>X252</th>\n",
       "      <th>X253</th>\n",
       "      <th>X254</th>\n",
       "      <th>X255</th>\n",
       "      <th>X256</th>\n",
       "      <th>X257</th>\n",
       "      <th>X258</th>\n",
       "      <th>X259</th>\n",
       "      <th>X260</th>\n",
       "      <th>X261</th>\n",
       "      <th>X262</th>\n",
       "      <th>X263</th>\n",
       "      <th>X264</th>\n",
       "      <th>X265</th>\n",
       "      <th>X266</th>\n",
       "      <th>X267</th>\n",
       "      <th>X268</th>\n",
       "      <th>X269</th>\n",
       "      <th>X270</th>\n",
       "      <th>X271</th>\n",
       "      <th>X272</th>\n",
       "      <th>X273</th>\n",
       "      <th>X274</th>\n",
       "      <th>X275</th>\n",
       "      <th>X276</th>\n",
       "      <th>X277</th>\n",
       "      <th>X278</th>\n",
       "      <th>X279</th>\n",
       "      <th>X280</th>\n",
       "      <th>X281</th>\n",
       "      <th>X282</th>\n",
       "      <th>X283</th>\n",
       "      <th>X284</th>\n",
       "      <th>X285</th>\n",
       "      <th>X286</th>\n",
       "      <th>X287</th>\n",
       "      <th>X288</th>\n",
       "      <th>X289</th>\n",
       "      <th>X290</th>\n",
       "      <th>X291</th>\n",
       "      <th>X292</th>\n",
       "      <th>X293</th>\n",
       "      <th>X294</th>\n",
       "      <th>X295</th>\n",
       "      <th>X296</th>\n",
       "      <th>X297</th>\n",
       "      <th>X298</th>\n",
       "      <th>X299</th>\n",
       "      <th>X300</th>\n",
       "      <th>X301</th>\n",
       "      <th>X302</th>\n",
       "      <th>X304</th>\n",
       "      <th>X305</th>\n",
       "      <th>X306</th>\n",
       "      <th>X307</th>\n",
       "      <th>X308</th>\n",
       "      <th>X309</th>\n",
       "      <th>X310</th>\n",
       "      <th>X311</th>\n",
       "      <th>X312</th>\n",
       "      <th>X313</th>\n",
       "      <th>X314</th>\n",
       "      <th>X315</th>\n",
       "      <th>X316</th>\n",
       "      <th>X317</th>\n",
       "      <th>X318</th>\n",
       "      <th>X319</th>\n",
       "      <th>X320</th>\n",
       "      <th>X321</th>\n",
       "      <th>X322</th>\n",
       "      <th>X323</th>\n",
       "      <th>X324</th>\n",
       "      <th>X325</th>\n",
       "      <th>X326</th>\n",
       "      <th>X327</th>\n",
       "      <th>X328</th>\n",
       "      <th>X329</th>\n",
       "      <th>X330</th>\n",
       "      <th>X331</th>\n",
       "      <th>X332</th>\n",
       "      <th>X333</th>\n",
       "      <th>X334</th>\n",
       "      <th>X335</th>\n",
       "      <th>X336</th>\n",
       "      <th>X337</th>\n",
       "      <th>X338</th>\n",
       "      <th>X339</th>\n",
       "      <th>X340</th>\n",
       "      <th>X341</th>\n",
       "      <th>X342</th>\n",
       "      <th>X343</th>\n",
       "      <th>X344</th>\n",
       "      <th>X345</th>\n",
       "      <th>X346</th>\n",
       "      <th>X347</th>\n",
       "      <th>X348</th>\n",
       "      <th>X349</th>\n",
       "      <th>X350</th>\n",
       "      <th>X351</th>\n",
       "      <th>X352</th>\n",
       "      <th>X353</th>\n",
       "      <th>X354</th>\n",
       "      <th>X355</th>\n",
       "      <th>X356</th>\n",
       "      <th>X357</th>\n",
       "      <th>X358</th>\n",
       "      <th>X359</th>\n",
       "      <th>X360</th>\n",
       "      <th>X361</th>\n",
       "      <th>X362</th>\n",
       "      <th>X363</th>\n",
       "      <th>X364</th>\n",
       "      <th>X365</th>\n",
       "      <th>X366</th>\n",
       "      <th>X367</th>\n",
       "      <th>X368</th>\n",
       "      <th>X369</th>\n",
       "      <th>X370</th>\n",
       "      <th>X371</th>\n",
       "      <th>X372</th>\n",
       "      <th>X373</th>\n",
       "      <th>X374</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81000</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53000</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         y X0 X1  X2 X3 X4 X5 X6 X8  X10  X11  X12  X13  X14  X15  X16  \\\n",
       "0   0 130.81000  k  v  at  a  d  u  j  o    0    0    0    1    0    0    0   \n",
       "1   6  88.53000  k  t  av  e  d  y  l  o    0    0    0    0    0    0    0   \n",
       "\n",
       "   X17  X18  X19  X20  X21  X22  X23  X24  X26  X27  X28  X29  X30  X31  X32  \\\n",
       "0    0    1    0    0    1    0    0    0    0    0    0    0    0    1    0   \n",
       "1    0    1    0    0    0    0    0    0    0    1    0    0    0    1    0   \n",
       "\n",
       "   X33  X34  X35  X36  X37  X38  X39  X40  X41  X42  X43  X44  X45  X46  X47  \\\n",
       "0    0    0    1    0    1    0    0    0    0    0    0    0    0    1    0   \n",
       "1    0    0    1    0    1    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   X48  X49  X50  X51  X52  X53  X54  X55  X56  X57  X58  X59  X60  X61  X62  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0   \n",
       "1    0    0    0    1    0    0    0    0    0    0    0    0    0    1    0   \n",
       "\n",
       "   X63  X64  X65  X66  X67  X68  X69  X70  X71  X73  X74  X75  X76  X77  X78  \\\n",
       "0    0    0    0    0    0    1    0    1    0    0    1    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    1    0    0    1    0    0    0    0   \n",
       "\n",
       "   X79  X80  X81  X82  X83  X84  X85  X86  X87  X88  X89  X90  X91  X92  X93  \\\n",
       "0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0   \n",
       "1    0    1    0    0    0    0    1    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   X94  X95  X96  X97  X98  X99  X100  X101  X102  X103  X104  X105  X106  \\\n",
       "0    0    0    0    0    0    0     0     0     0     0     0     0     0   \n",
       "1    0    0    1    0    1    0     1     1     0     0     0     0     0   \n",
       "\n",
       "   X107  X108  X109  X110  X111  X112  X113  X114  X115  X116  X117  X118  \\\n",
       "0     0     0     0     0     1     0     0     1     0     1     0     1   \n",
       "1     0     0     0     0     1     0     0     0     0     0     0     1   \n",
       "\n",
       "   X119  X120  X122  X123  X124  X125  X126  X127  X128  X129  X130  X131  \\\n",
       "0     1     1     0     0     0     0     0     0     1     0     0     1   \n",
       "1     1     1     0     0     0     0     0     1     1     0     0     0   \n",
       "\n",
       "   X132  X133  X134  X135  X136  X137  X138  X139  X140  X141  X142  X143  \\\n",
       "0     0     0     0     0     1     1     0     0     0     0     1     0   \n",
       "1     1     0     0     0     1     0     0     0     0     0     1     0   \n",
       "\n",
       "   X144  X145  X146  X147  X148  X150  X151  X152  X153  X154  X155  X156  \\\n",
       "0     1     0     0     0     0     1     0     0     0     0     0     1   \n",
       "1     1     0     0     0     0     1     0     0     0     0     0     1   \n",
       "\n",
       "   X157  X158  X159  X160  X161  X162  X163  X164  X165  X166  X167  X168  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     1     0     0     0   \n",
       "\n",
       "   X169  X170  X171  X172  X173  X174  X175  X176  X177  X178  X179  X180  \\\n",
       "0     0     1     0     0     0     0     0     0     0     0     1     0   \n",
       "1     0     0     0     0     0     0     0     0     0     1     0     0   \n",
       "\n",
       "   X181  X182  X183  X184  X185  X186  X187  X189  X190  X191  X192  X194  \\\n",
       "0     0     0     0     1     0     0     1     1     0     0     0     1   \n",
       "1     0     0     0     0     0     0     1     1     0     0     0     1   \n",
       "\n",
       "   X195  X196  X197  X198  X199  X200  X201  X202  X203  X204  X205  X206  \\\n",
       "0     0     0     0     0     0     0     0     0     0     1     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     1     0   \n",
       "\n",
       "   X207  X208  X209  X210  X211  X212  X213  X214  X215  X216  X217  X218  \\\n",
       "0     0     0     1     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     1     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   X219  X220  X221  X222  X223  X224  X225  X226  X227  X228  X229  X230  \\\n",
       "0     0     1     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     1     0   \n",
       "\n",
       "   X231  X232  X233  X234  X235  X236  X237  X238  X239  X240  X241  X242  \\\n",
       "0     0     0     0     1     0     0     1     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "\n",
       "   X243  X244  X245  X246  X247  X248  X249  X250  X251  X252  X253  X254  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     1     0     0     0     0   \n",
       "\n",
       "   X255  X256  X257  X258  X259  X260  X261  X262  X263  X264  X265  X266  \\\n",
       "0     0     0     0     0     0     0     0     1     1     0     0     1   \n",
       "1     0     0     0     0     0     0     0     0     1     0     1     0   \n",
       "\n",
       "   X267  X268  X269  X270  X271  X272  X273  X274  X275  X276  X277  X278  \\\n",
       "0     0     0     0     0     0     0     1     0     1     0     0     0   \n",
       "1     0     0     0     0     0     0     1     0     1     0     0     0   \n",
       "\n",
       "   X279  X280  X281  X282  X283  X284  X285  X286  X287  X288  X289  X290  \\\n",
       "0     0     0     0     0     0     0     1     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     1     0     0     0     0     0   \n",
       "\n",
       "   X291  X292  X293  X294  X295  X296  X297  X298  X299  X300  X301  X302  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   X304  X305  X306  X307  X308  X309  X310  X311  X312  X313  X314  X315  \\\n",
       "0     0     0     1     0     0     0     0     0     0     0     0     0   \n",
       "1     1     0     0     0     0     0     0     1     0     0     0     0   \n",
       "\n",
       "   X316  X317  X318  X319  X320  X321  X322  X323  X324  X325  X326  X327  \\\n",
       "0     1     0     0     0     0     0     0     0     1     0     0     1   \n",
       "1     1     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   X328  X329  X330  X331  X332  X333  X334  X335  X336  X337  X338  X339  \\\n",
       "0     0     1     0     0     0     0     1     0     0     0     0     0   \n",
       "1     0     1     0     0     0     0     0     0     1     1     0     0   \n",
       "\n",
       "   X340  X341  X342  X343  X344  X345  X346  X347  X348  X349  X350  X351  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     1     0     0     0   \n",
       "\n",
       "   X352  X353  X354  X355  X356  X357  X358  X359  X360  X361  X362  X363  \\\n",
       "0     0     0     1     0     0     0     0     0     0     1     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     1     0     1   \n",
       "\n",
       "   X364  X365  X366  X367  X368  X369  X370  X371  X372  X373  X374  X375  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     1   \n",
       "\n",
       "   X376  X377  X378  X379  X380  X382  X383  X384  X385  \n",
       "0     0     1     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "init_train = pd.read_csv(\"raw_data/train.csv\")\n",
    "init_test = pd.read_csv(\"raw_data/test.csv\")\n",
    "\n",
    "display(init_train.shape)\n",
    "display(init_train.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define probe df\n",
    "probe_ids = [1, 12, 23, 28, 42, \n",
    "             43, 45, 57, 72, 78, \n",
    "             88, 89, 93, 94, 104, \n",
    "             105, 110, 253, 259, 262, \n",
    "             289, 337, 409, 437, 488, \n",
    "             493, 973, 1001, 1004, 1008, \n",
    "             1009, 1259, 1644, 1652, 1664, \n",
    "             2129, 2342, 3853, 3977, 4958, \n",
    "             4960, 7055, 7805, 8002, 8007, \n",
    "             8416]\n",
    "probe_values = [71.34112, 109.30903, 115.21953, 92.00675, 87.73572, \n",
    "                129.79876, 99.55671, 116.02167, 110.54742, 125.28849, \n",
    "                90.33211, 130.55165, 105.79792, 103.04672, 92.37968, \n",
    "                108.5069, 87.70757, 115.93724, 93.33662, 75.35182, \n",
    "                89.27667, 101.23135, 91.00760, 85.96960, 113.39009, \n",
    "                108.40135, 106.76189, 111.65212, 91.472, 106.71967, \n",
    "                108.21841, 112.3909, 99.14157, 89.77625, 112.93977, \n",
    "                112.03, 93.06, 105.481283411, 132.08556, 113.58711, \n",
    "                89.83957, 91.549, 105.8472, 95.84858, 87.44019, \n",
    "                96.84773]\n",
    "new_train = init_test[init_test[\"ID\"].isin(probe_ids)]\n",
    "new_y = pd.DataFrame({\"y\" : probe_values})\n",
    "new_y.set_index(new_train.index, inplace = True)\n",
    "probe_df = pd.concat([new_train, new_y], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc7\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'LE', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.577337826405\n",
      "Elapsed : 23.388359785079956\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc13\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'LE', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.572452943605\n",
      "Elapsed : 26.3050274848938\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc9\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'LE', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.570493135565\n",
      "Elapsed : 26.616647958755493\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc11\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'LE', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.569623012406\n",
      "Elapsed : 24.912009477615356\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc10\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'dummies', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.564764668793\n",
      "Elapsed : 36.63447976112366\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc16\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'dummies', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.567532970339\n",
      "Elapsed : 29.781832218170166\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc1\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'LE', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.576493308265\n",
      "Elapsed : 25.825690746307373\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc14\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'dummies', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.567056775461\n",
      "Elapsed : 35.256094455718994\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc15\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'LE', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.571842558259\n",
      "Elapsed : 23.91415238380432\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc3\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'LE', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.577267847646\n",
      "Elapsed : 23.59061908721924\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc8\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'dummies', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.57235862761\n",
      "Elapsed : 29.550586938858032\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc4\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'dummies', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.571123754386\n",
      "Elapsed : 29.88789677619934\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc2\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'dummies', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.570913568385\n",
      "Elapsed : 35.43165683746338\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc6\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'dummies', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.570922349334\n",
      "Elapsed : 34.98126530647278\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc5\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 10, 'tsvd': 10, 'encode_cats': 'LE', 'dupli_rows': 'median', 'constant_vars': 'without', 'log_target': 10, 'grp': 10, 'mean_x': 8, 'srp': 6, 'probe': 'false'}\n",
      "Global OOF r2_score : 0.57693575234\n",
      "Elapsed : 27.460891723632812\n",
      "***** MODEL : zl ***************\n",
      "***** CONFIG : dc12\n",
      "{'ica': 0, 'dupli_vars': 'without', 'binary_counts': 'with', 'pca': 0, 'tsvd': 0, 'encode_cats': 'dummies', 'dupli_rows': False, 'constant_vars': 'without', 'log_target': 10, 'grp': 0, 'mean_x': 8, 'srp': 0, 'probe': 'true'}\n",
      "Global OOF r2_score : 0.564613510054\n",
      "Elapsed : 31.41930365562439\n"
     ]
    }
   ],
   "source": [
    "# Generate preds\n",
    "results = run_generator(models, data_configs, init_train, init_test, probe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>conf</th>\n",
       "      <th>cv</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc7</td>\n",
       "      <td>0.57734</td>\n",
       "      <td>23.38836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc3</td>\n",
       "      <td>0.57727</td>\n",
       "      <td>23.59062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc5</td>\n",
       "      <td>0.57694</td>\n",
       "      <td>27.46089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc1</td>\n",
       "      <td>0.57649</td>\n",
       "      <td>25.82569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc13</td>\n",
       "      <td>0.57245</td>\n",
       "      <td>26.30503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc8</td>\n",
       "      <td>0.57236</td>\n",
       "      <td>29.55059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc15</td>\n",
       "      <td>0.57184</td>\n",
       "      <td>23.91415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc4</td>\n",
       "      <td>0.57112</td>\n",
       "      <td>29.88790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc6</td>\n",
       "      <td>0.57092</td>\n",
       "      <td>34.98127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc2</td>\n",
       "      <td>0.57091</td>\n",
       "      <td>35.43166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc9</td>\n",
       "      <td>0.57049</td>\n",
       "      <td>26.61665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc11</td>\n",
       "      <td>0.56962</td>\n",
       "      <td>24.91201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc16</td>\n",
       "      <td>0.56753</td>\n",
       "      <td>29.78183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc14</td>\n",
       "      <td>0.56706</td>\n",
       "      <td>35.25609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc10</td>\n",
       "      <td>0.56476</td>\n",
       "      <td>36.63448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zl</td>\n",
       "      <td>dc12</td>\n",
       "      <td>0.56461</td>\n",
       "      <td>31.41930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  conf      cv     time\n",
       "0    zl   dc7 0.57734 23.38836\n",
       "1    zl   dc3 0.57727 23.59062\n",
       "2    zl   dc5 0.57694 27.46089\n",
       "3    zl   dc1 0.57649 25.82569\n",
       "4    zl  dc13 0.57245 26.30503\n",
       "5    zl   dc8 0.57236 29.55059\n",
       "6    zl  dc15 0.57184 23.91415\n",
       "7    zl   dc4 0.57112 29.88790\n",
       "8    zl   dc6 0.57092 34.98127\n",
       "9    zl   dc2 0.57091 35.43166\n",
       "10   zl   dc9 0.57049 26.61665\n",
       "11   zl  dc11 0.56962 24.91201\n",
       "12   zl  dc16 0.56753 29.78183\n",
       "13   zl  dc14 0.56706 35.25609\n",
       "14   zl  dc10 0.56476 36.63448\n",
       "15   zl  dc12 0.56461 31.41930"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show ordered results\n",
    "results.sort_values([\"cv\"], ascending = False, inplace= True)\n",
    "results.reset_index(drop = True, inplace = True)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Optimize parameters for most promising models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
