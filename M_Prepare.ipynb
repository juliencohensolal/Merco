{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA, FastICA, TruncatedSVD\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "\n",
    "# Definitions\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore')\n",
    "N_JOBS = -1\n",
    "SEED = 420\n",
    "SHIFT = 5\n",
    "FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.810</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.530</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y X0 X1  X2 X3 X4 X5 X6 X8  ...   X375  X376  X377  X378  X379  \\\n",
       "0   0 130.810  k  v  at  a  d  u  j  o  ...      0     0     1     0     0   \n",
       "1   6  88.530  k  t  av  e  d  y  l  o  ...      1     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 378 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4209, 377)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>b</td>\n",
       "      <td>ai</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  X0 X1  X2 X3 X4 X5 X6 X8  X10  ...   X375  X376  X377  X378  X379  \\\n",
       "0   1  az  v   n  f  d  t  a  w    0  ...      0     0     0     1     0   \n",
       "1   2   t  b  ai  a  d  b  g  y    0  ...      0     0     1     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 377 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "train = pd.read_csv(\"raw_data/train.csv\")\n",
    "test = pd.read_csv(\"raw_data/test.csv\")\n",
    "\n",
    "display(train.shape)\n",
    "display(train.head(2))\n",
    "display(test.shape)\n",
    "display(test.head(2))\n",
    "\n",
    "# Save test IDs for predictions\n",
    "test_ids = test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# METHOD 1 : remove the one biggest outlier\\noldNbRows = train.shape[0]\\ntrain = train[train.y < 250]\\nprint(\"Removing the most extreme outliers : \" + str(oldNbRows - train.shape[0]))\\nprint(\"train : \" + str(train.shape))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove outliers?\n",
    "\n",
    "'''# METHOD 1 : remove the one biggest outlier\n",
    "oldNbRows = train.shape[0]\n",
    "train = train[train.y < 250]\n",
    "print(\"Removing the most extreme outliers : \" + str(oldNbRows - train.shape[0]))\n",
    "print(\"train : \" + str(train.shape))'''\n",
    "\n",
    "# METHOD 2 : do nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# METHOD 2 : apply a transfo on y to make it more \"normal\"\\ny = pd.DataFrame({\"y\": np.log1p(train.y + SHIFT)}, columns = [\"y\"])'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target\n",
    "\n",
    "# METHOD 1 : take y as is\n",
    "y = pd.DataFrame({\"y\": train.y})\n",
    "\n",
    "'''# METHOD 2 : apply a transfo on y to make it more \"normal\"\n",
    "y = pd.DataFrame({\"y\": np.log1p(train.y + SHIFT)}, columns = [\"y\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Handle cat features\n",
    "\n",
    "'''# METHOD 1 : convert into dummy variables\n",
    "alldata = pd.concat([train.drop(\"y\", axis = 1), test], axis = 0)\n",
    "alldata = pd.get_dummies(alldata).astype(int)\n",
    "train = alldata.iloc[:train.shape[0], :]\n",
    "test = alldata.iloc[train.shape[0]: , :]'''\n",
    "\n",
    "'''# METHOD 2 : use LabelEncoder (assumes some order in values)\n",
    "for c in train.drop(\"y\", axis = 1).columns:\n",
    "    if train[c].dtype == \"object\" :\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))'''\n",
    "\n",
    "# METHOD 3 : use LabelEncoder with other order (after a will be b, not aa)\n",
    "def encodeLetters(charcode) : \n",
    "    code = 0\n",
    "    length = len(str(charcode))\n",
    "    for i in range(length) :\n",
    "        # example : AC = 1 * 26 ^ 1 + 3 * 26 ^ 0\n",
    "        code += (ord(str(charcode)[i]) - ord(\"a\") + 1) * (26 ** (length - i - 1)) - 1\n",
    "    return(code)\n",
    "\n",
    "for c in train.drop(\"y\", axis = 1).columns:\n",
    "    if train[c].dtype == \"object\" :\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(train[c].values) + list(test[c].values)) \n",
    "        train[c] = train[c].apply(encodeLetters)\n",
    "        test[c] = test[c].apply(encodeLetters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing constant variables : ['X11', 'X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290', 'X293', 'X297', 'X330', 'X347']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# METHOD 2 : do nothing'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features with no information (unique value in train set) ?\n",
    "\n",
    "# METHOD 1 : Remove those\n",
    "constant_vars = []\n",
    "for col in train.drop(\"y\", axis = 1).columns:\n",
    "    if(train[col].nunique() == 1):\n",
    "        constant_vars.append(col)\n",
    "print(\"Removing constant variables : \" + str(constant_vars))\n",
    "train.drop(constant_vars, axis = 1, inplace = True)\n",
    "test.drop(constant_vars, axis = 1, inplace = True)\n",
    "\n",
    "'''# METHOD 2 : do nothing'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 34 duplicate variables\n",
      "['X102', 'X113', 'X119', 'X134', 'X146', 'X147', 'X172', 'X199', 'X213', 'X214', 'X216', 'X222', 'X226', 'X227', 'X239', 'X244', 'X253', 'X254', 'X262', 'X279', 'X296', 'X299', 'X302', 'X324', 'X326', 'X35', 'X360', 'X364', 'X37', 'X382', 'X385', 'X39', 'X76', 'X84']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# METHOD 3 : do nothing'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle duplicate variables\n",
    "def findDuplicateVars(df) :\n",
    "    cols = df.columns\n",
    "    removed_cols = []\n",
    "    for i in range(len(cols) - 1) :\n",
    "        v = df[cols[i]].values\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            if np.array_equal(v, df[cols[j]].values) :\n",
    "                #print(\"Dups : \" + str(cols[i]) + \" and \" + str(cols[j]))\n",
    "                removed_cols.append(cols[j])\n",
    "    return(removed_cols)\n",
    "\n",
    "\n",
    "# METHOD 1 : Drop variables which are duplicate in train + test\n",
    "old_nb_vars = train.shape[1]\n",
    "alldata = pd.concat([train.drop(\"y\", axis = 1), test], axis = 0)\n",
    "removed_vars = findDuplicateVars(alldata)\n",
    "removed_vars = list(set(removed_vars))\n",
    "train.drop(removed_vars, axis = 1, inplace = True)\n",
    "test.drop(removed_vars, axis = 1, inplace = True)\n",
    "print(\"Removed \" + str(old_nb_vars - train.shape[1]) + \" duplicate variables\")\n",
    "print(sorted(removed_vars))\n",
    "\n",
    "'''# METHOD 2 : Drop variables which are duplicate just in train\n",
    "old_nb_vars = train.shape[1]\n",
    "removed_vars = findDuplicateVars(train)\n",
    "removed_vars = list(set(removed_vars))\n",
    "train.drop(removed_vars, axis = 1, inplace = True)\n",
    "test.drop(removed_vars, axis = 1, inplace = True)\n",
    "print(\"Removed \" + str(old_nb_vars - train.shape[1]) + \" duplicate variables\")\n",
    "print(sorted(removed_vars))'''\n",
    "\n",
    "'''# METHOD 3 : do nothing'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add columns with count of 1s for each binary col\n",
    "binary_vars = list(set(train.columns.drop([\"ID\", \"y\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"])))\n",
    "train[\"bin_ones\"] = (train[binary_vars] == 1).astype(int).sum(axis = 1)\n",
    "test[\"bin_ones\"] = (test[binary_vars] == 1).astype(int).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add top X PCA components\n",
    "N_COMP = 12\n",
    "pca = PCA(n_components = N_COMP, random_state = SEED)\n",
    "pca_train = pca.fit_transform(train.drop(\"y\", axis = 1))\n",
    "pca_test = pca.transform(test)\n",
    "\n",
    "# Add top X ICA components\n",
    "N_COMP = 12\n",
    "ica = FastICA(n_components = N_COMP, random_state = SEED)\n",
    "ica_train = ica.fit_transform(train.drop(\"y\", axis = 1))\n",
    "ica_test = ica.transform(test)\n",
    "\n",
    "# Add top X T-SVD components\n",
    "N_COMP = 12\n",
    "tsvd = TruncatedSVD(n_components = N_COMP, random_state = SEED)\n",
    "tsvd_train = tsvd.fit_transform(train.drop(\"y\", axis = 1))\n",
    "tsvd_test = tsvd.transform(test)\n",
    "\n",
    "# Add top X GaussianRandomProjection components\n",
    "N_COMP = 12\n",
    "grp = GaussianRandomProjection(n_components = N_COMP, random_state = SEED)\n",
    "grp_train = grp.fit_transform(train.drop(\"y\", axis = 1))\n",
    "grp_test = grp.transform(test)\n",
    "\n",
    "# Add top X SparseRandomProjection components\n",
    "N_COMP = 12\n",
    "srp = SparseRandomProjection(n_components = N_COMP, random_state = SEED)\n",
    "srp_train = srp.fit_transform(train.drop(\"y\", axis = 1))\n",
    "srp_test = srp.transform(test)\n",
    "\n",
    "for i in range(1, N_COMP + 1) :\n",
    "    train[\"pca_\" + str(i)] = pca_train[:, i - 1]\n",
    "    test[\"pca_\" + str(i)] = pca_test[:, i - 1]\n",
    "    \n",
    "    train[\"ica_\" + str(i)] = ica_train[:, i - 1]\n",
    "    test[\"ica_\" + str(i)] = ica_test[:, i - 1]\n",
    "    \n",
    "    train[\"tsvd_\" + str(i)] = tsvd_train[:, i - 1]\n",
    "    test[\"tsvd_\" + str(i)] = tsvd_test[:, i - 1]\n",
    "    \n",
    "    train[\"grp_\" + str(i)] = grp_train[:, i - 1]\n",
    "    test[\"grp_\" + str(i)] = grp_test[:, i - 1]\n",
    "    \n",
    "    train[\"srp_\" + str(i)] = srp_train[:, i - 1]\n",
    "    test[\"srp_\" + str(i)] = srp_test[:, i - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# METHOD 3\\ntest[\"y_x0\"].fillna(test[\"y_x0\"].dropna().min(), inplace = True)\\ntest[\"y_x1\"].fillna(test[\"y_x1\"].dropna().min(), inplace = True)\\ntest[\"y_x2\"].fillna(test[\"y_x2\"].dropna().min(), inplace = True)\\ntest[\"y_x3\"].fillna(test[\"y_x3\"].dropna().min(), inplace = True)\\ntest[\"y_x4\"].fillna(test[\"y_x4\"].dropna().min(), inplace = True)\\ntest[\"y_x5\"].fillna(test[\"y_x5\"].dropna().min(), inplace = True)\\ntest[\"y_x6\"].fillna(test[\"y_x6\"].dropna().min(), inplace = True)\\ntest[\"y_x8\"].fillna(test[\"y_x8\"].dropna().min(), inplace = True)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add median/mean/min of y for X0-X8\n",
    "\n",
    "'''# METHOD 1 \n",
    "y_x0 = train[[\"X0\", \"y\"]].groupby([\"X0\"], as_index = False).mean()\n",
    "y_x1 = train[[\"X1\", \"y\"]].groupby([\"X1\"], as_index = False).mean()\n",
    "y_x2 = train[[\"X2\", \"y\"]].groupby([\"X2\"], as_index = False).mean()\n",
    "y_x3 = train[[\"X3\", \"y\"]].groupby([\"X3\"], as_index = False).mean()\n",
    "y_x4 = train[[\"X4\", \"y\"]].groupby([\"X4\"], as_index = False).mean()\n",
    "y_x5 = train[[\"X5\", \"y\"]].groupby([\"X5\"], as_index = False).mean()\n",
    "y_x6 = train[[\"X6\", \"y\"]].groupby([\"X6\"], as_index = False).mean()\n",
    "y_x8 = train[[\"X8\", \"y\"]].groupby([\"X8\"], as_index = False).mean()'''\n",
    "\n",
    "'''# METHOD 2\n",
    "y_x0 = train[[\"X0\", \"y\"]].groupby([\"X0\"], as_index = False).median()\n",
    "y_x1 = train[[\"X1\", \"y\"]].groupby([\"X1\"], as_index = False).median()\n",
    "y_x2 = train[[\"X2\", \"y\"]].groupby([\"X2\"], as_index = False).median()\n",
    "y_x3 = train[[\"X3\", \"y\"]].groupby([\"X3\"], as_index = False).median()\n",
    "y_x4 = train[[\"X4\", \"y\"]].groupby([\"X4\"], as_index = False).median()\n",
    "y_x5 = train[[\"X5\", \"y\"]].groupby([\"X5\"], as_index = False).median()\n",
    "y_x6 = train[[\"X6\", \"y\"]].groupby([\"X6\"], as_index = False).median()\n",
    "y_x8 = train[[\"X8\", \"y\"]].groupby([\"X8\"], as_index = False).median()'''\n",
    "\n",
    "'''# METHOD 3\n",
    "y_x0 = train[[\"X0\", \"y\"]].groupby([\"X0\"], as_index = False).min()\n",
    "y_x1 = train[[\"X1\", \"y\"]].groupby([\"X1\"], as_index = False).min()\n",
    "y_x2 = train[[\"X2\", \"y\"]].groupby([\"X2\"], as_index = False).min()\n",
    "y_x3 = train[[\"X3\", \"y\"]].groupby([\"X3\"], as_index = False).min()\n",
    "y_x4 = train[[\"X4\", \"y\"]].groupby([\"X4\"], as_index = False).min()\n",
    "y_x5 = train[[\"X5\", \"y\"]].groupby([\"X5\"], as_index = False).min()\n",
    "y_x6 = train[[\"X6\", \"y\"]].groupby([\"X6\"], as_index = False).min()\n",
    "y_x8 = train[[\"X8\", \"y\"]].groupby([\"X8\"], as_index = False).min()'''\n",
    "\n",
    "'''y_x0.columns = [\"X0\", \"y_x0\"]\n",
    "y_x1.columns = [\"X1\", \"y_x1\"]\n",
    "y_x2.columns = [\"X2\", \"y_x2\"]\n",
    "y_x3.columns = [\"X3\", \"y_x3\"]\n",
    "y_x4.columns = [\"X4\", \"y_x4\"]\n",
    "y_x5.columns = [\"X5\", \"y_x5\"]\n",
    "y_x6.columns = [\"X6\", \"y_x6\"]\n",
    "y_x8.columns = [\"X8\", \"y_x8\"]\n",
    "train = pd.merge(train, y_x0, on = \"X0\", how = \"outer\")\n",
    "train = pd.merge(train, y_x1, on = \"X1\", how = \"outer\")\n",
    "train = pd.merge(train, y_x2, on = \"X2\", how = \"outer\")\n",
    "train = pd.merge(train, y_x3, on = \"X3\", how = \"outer\")\n",
    "train = pd.merge(train, y_x4, on = \"X4\", how = \"outer\")\n",
    "train = pd.merge(train, y_x5, on = \"X5\", how = \"outer\")\n",
    "train = pd.merge(train, y_x6, on = \"X6\", how = \"outer\")\n",
    "train = pd.merge(train, y_x8, on = \"X8\", how = \"outer\")\n",
    "test = pd.merge(test, y_x0, on = \"X0\", how = \"left\")\n",
    "test = pd.merge(test, y_x1, on = \"X1\", how = \"left\")\n",
    "test = pd.merge(test, y_x2, on = \"X2\", how = \"left\")\n",
    "test = pd.merge(test, y_x3, on = \"X3\", how = \"left\")\n",
    "test = pd.merge(test, y_x4, on = \"X4\", how = \"left\")\n",
    "test = pd.merge(test, y_x5, on = \"X5\", how = \"left\")\n",
    "test = pd.merge(test, y_x6, on = \"X6\", how = \"left\")\n",
    "test = pd.merge(test, y_x8, on = \"X8\", how = \"left\")'''\n",
    "\n",
    "'''# METHOD 1\n",
    "test[\"y_x0\"].fillna(test[\"y_x0\"].dropna().mean(), inplace = True)\n",
    "test[\"y_x1\"].fillna(test[\"y_x1\"].dropna().mean(), inplace = True)\n",
    "test[\"y_x2\"].fillna(test[\"y_x2\"].dropna().mean(), inplace = True)\n",
    "test[\"y_x3\"].fillna(test[\"y_x3\"].dropna().mean(), inplace = True)\n",
    "test[\"y_x4\"].fillna(test[\"y_x4\"].dropna().mean(), inplace = True)\n",
    "test[\"y_x5\"].fillna(test[\"y_x5\"].dropna().mean(), inplace = True)\n",
    "test[\"y_x6\"].fillna(test[\"y_x6\"].dropna().mean(), inplace = True)\n",
    "test[\"y_x8\"].fillna(test[\"y_x8\"].dropna().mean(), inplace = True)'''\n",
    "\n",
    "'''# METHOD 2\n",
    "test[\"y_x0\"].fillna(test[\"y_x0\"].dropna().median(), inplace = True)\n",
    "test[\"y_x1\"].fillna(test[\"y_x1\"].dropna().median(), inplace = True)\n",
    "test[\"y_x2\"].fillna(test[\"y_x2\"].dropna().median(), inplace = True)\n",
    "test[\"y_x3\"].fillna(test[\"y_x3\"].dropna().median(), inplace = True)\n",
    "test[\"y_x4\"].fillna(test[\"y_x4\"].dropna().median(), inplace = True)\n",
    "test[\"y_x5\"].fillna(test[\"y_x5\"].dropna().median(), inplace = True)\n",
    "test[\"y_x6\"].fillna(test[\"y_x6\"].dropna().median(), inplace = True)\n",
    "test[\"y_x8\"].fillna(test[\"y_x8\"].dropna().median(), inplace = True)'''\n",
    "\n",
    "'''# METHOD 3\n",
    "test[\"y_x0\"].fillna(test[\"y_x0\"].dropna().min(), inplace = True)\n",
    "test[\"y_x1\"].fillna(test[\"y_x1\"].dropna().min(), inplace = True)\n",
    "test[\"y_x2\"].fillna(test[\"y_x2\"].dropna().min(), inplace = True)\n",
    "test[\"y_x3\"].fillna(test[\"y_x3\"].dropna().min(), inplace = True)\n",
    "test[\"y_x4\"].fillna(test[\"y_x4\"].dropna().min(), inplace = True)\n",
    "test[\"y_x5\"].fillna(test[\"y_x5\"].dropna().min(), inplace = True)\n",
    "test[\"y_x6\"].fillna(test[\"y_x6\"].dropna().min(), inplace = True)\n",
    "test[\"y_x8\"].fillna(test[\"y_x8\"].dropna().min(), inplace = True)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# METHOD 3 : keep the row with the lowest y \\ntrain = train[cols_to_apply].groupby(cols_to_groupby, as_index = False).min()\\ntrain.columns = cols_to_apply'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle duplicate rows\n",
    "'''cols_to_groupby = [k for k in train.columns if k not in [\"ID\", \"y\"]] \n",
    "cols_to_apply = cols_to_groupby + [\"y\"]'''\n",
    "\n",
    "'''# METHOD 1 : take mean of duplicate rows\n",
    "train = train[cols_to_apply].groupby(cols_to_groupby, as_index = False).mean()\n",
    "train.columns = cols_to_apply'''\n",
    "\n",
    "'''# METHOD 2 : take median of duplicate rows\n",
    "train = train[cols_to_apply].groupby(cols_to_groupby, as_index = False).median()\n",
    "train.columns = cols_to_apply'''\n",
    "\n",
    "'''# METHOD 3 : keep the row with the lowest y \n",
    "train = train[cols_to_apply].groupby(cols_to_groupby, as_index = False).min()\n",
    "train.columns = cols_to_apply'''\n",
    "\n",
    "# METHOD 4 : do nothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Concatenate train and test for global preprocessing\\nalldata = pd.concat([train, test], axis = 0)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Concatenate train and test for global preprocessing\n",
    "alldata = pd.concat([train, test], axis = 0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Differentiate numerical features and categorical features\\ncat_feats = test.select_dtypes(include = [\"object\"]).columns\\nprint(\"Categorical features : \" + str(len(cat_feats)))\\nnum_feats = test.select_dtypes(exclude = [\"object\"]).columns\\nprint(\"Numerical features : \" + str(len(num_feats)))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Differentiate numerical features and categorical features\n",
    "cat_feats = test.select_dtypes(include = [\"object\"]).columns\n",
    "print(\"Categorical features : \" + str(len(cat_feats)))\n",
    "num_feats = test.select_dtypes(exclude = [\"object\"]).columns\n",
    "print(\"Numerical features : \" + str(len(num_feats)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Redifferentiate train and test sets\\ntrain = alldata.iloc[:train.shape[0], :]\\ntest = alldata.iloc[train.shape[0]: , :]\\ncols = train.columns'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Redifferentiate train and test sets\n",
    "train = alldata.iloc[:train.shape[0], :]\n",
    "test = alldata.iloc[train.shape[0]: , :]\n",
    "cols = train.columns'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add AND and OR operations on top/all binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add simpler groups of cat features (diminish cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Validation set for ensembling\n",
    "X_test = train.drop(\"y\", axis = 1).sample(frac = (1 / FOLDS), random_state = SEED)\n",
    "X_train = train.drop(\"y\", axis = 1).drop(X_test.index, axis = 0)\n",
    "\n",
    "X_test_y = y.sample(frac = (1 / FOLDS), random_state = SEED)\n",
    "X_train_y = y.drop(X_test_y.index, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write data in CSV files\n",
    "train.drop(\"y\", axis = 1, inplace = True)\n",
    "\n",
    "train.to_csv(\"clean_data/train\" + \".csv\", index = False)\n",
    "y.to_csv(\"clean_data/y.csv\", index = False)\n",
    "\n",
    "X_train.to_csv(\"clean_data/X_train\" + \".csv\", index = False)\n",
    "X_train_y.to_csv(\"clean_data/X_train_y.csv\", index = False)\n",
    "\n",
    "X_test.to_csv(\"clean_data/X_test\" + \".csv\", index = False)\n",
    "X_test_y.to_csv(\"clean_data/X_test_y.csv\", index = False)\n",
    "\n",
    "test.to_csv(\"clean_data/test\" + \".csv\", index = False)\n",
    "test_ids.to_csv(\"clean_data/test_ids.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
