{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import display\n",
    "\n",
    "# Definitions\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore')\n",
    "N_JOBS = -1\n",
    "SEED = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stack all single Level 1 models OOF and test preds as entries for a Level 2 model\n",
    "def get_level_one_outputs(OOF_targets) :\n",
    "    level_one_OOF = pd.DataFrame()\n",
    "    i = 0\n",
    "    root_dir = \"oof_preds/\"\n",
    "    for file_name in sorted(os.listdir(root_dir)) :\n",
    "        preds_OOF = pd.read_csv(root_dir + file_name)\n",
    "        cur_preds_OOF = pd.Series(preds_OOF.y, name = file_name[0:7])\n",
    "        level_one_OOF = pd.concat([level_one_OOF, cur_preds_OOF], axis = 1)\n",
    "        i += 1\n",
    "    display(level_one_OOF.head())\n",
    "\n",
    "    # Same for test set preds\n",
    "    level_one_test = pd.DataFrame()\n",
    "    i = 0\n",
    "    root_dir = \"preds/\"\n",
    "    for file_name in sorted(os.listdir(root_dir)) :\n",
    "        preds_test = pd.read_csv(root_dir + file_name)\n",
    "        cur_preds_test = pd.Series(preds_test.y, name = file_name[0:7])\n",
    "        level_one_test = pd.concat([level_one_test, cur_preds_test], axis = 1)\n",
    "        i += 1\n",
    "    display(level_one_test.head())\n",
    "    \n",
    "    return(level_one_OOF, level_one_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Define function to minimize\\ndef target_func(weights) :\\n    final_prediction = 0\\n    for weight, prediction in zip(weights, preds_X_test):\\n        final_prediction += weight * prediction\\n    return(-r2_score(X_test_y, final_prediction))\\n\\n\\n# Optimize ensemble weights on held out fold\\ndef optimize(preds_X_test, names) :\\n    scores = []\\n    weights = []\\n    for i in range(100):\\n        # Choose many random starting weights\\n        starting_values = np.random.uniform(size = len(preds_X_test))\\n\\n        # Our weights are bound between 0 and 1\\n        bounds = [(0, 1)] * len(preds_X_test)\\n\\n        res = minimize(\\n            target_func, \\n            starting_values, \\n            method = \"SLSQP\", \\n            bounds = bounds, \\n            options = {\"maxiter\" : 10000})\\n\\n        scores.append(res[\"fun\"])\\n        weights.append(res[\"x\"])\\n\\n    bestSC = -np.min(scores)\\n    bestWght = weights[np.argmin(scores)]\\n\\n    print(\"\\n Ensemble Score: {}\".format(bestSC))\\n    print(\"\\n Best Weights: {}\".format(bestWght))\\n    print(\"\\n Names: {}\".format(names))\\n\\n    return(bestSC, bestWght, names)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Define function to minimize\n",
    "def target_func(weights) :\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, preds_X_test):\n",
    "        final_prediction += weight * prediction\n",
    "    return(-r2_score(X_test_y, final_prediction))\n",
    "\n",
    "\n",
    "# Optimize ensemble weights on held out fold\n",
    "def optimize(preds_X_test, names) :\n",
    "    scores = []\n",
    "    weights = []\n",
    "    for i in range(100):\n",
    "        # Choose many random starting weights\n",
    "        starting_values = np.random.uniform(size = len(preds_X_test))\n",
    "\n",
    "        # Our weights are bound between 0 and 1\n",
    "        bounds = [(0, 1)] * len(preds_X_test)\n",
    "\n",
    "        res = minimize(\n",
    "            target_func, \n",
    "            starting_values, \n",
    "            method = \"SLSQP\", \n",
    "            bounds = bounds, \n",
    "            options = {\"maxiter\" : 10000})\n",
    "\n",
    "        scores.append(res[\"fun\"])\n",
    "        weights.append(res[\"x\"])\n",
    "\n",
    "    bestSC = -np.min(scores)\n",
    "    bestWght = weights[np.argmin(scores)]\n",
    "\n",
    "    print(\"\\n Ensemble Score: {}\".format(bestSC))\n",
    "    print(\"\\n Best Weights: {}\".format(bestWght))\n",
    "    print(\"\\n Names: {}\".format(names))\n",
    "\n",
    "    return(bestSC, bestWght, names)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to minimize\n",
    "def target_func(weights) :\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, preds_X_test):\n",
    "        final_prediction += weight * prediction\n",
    "    return(-r2_score(OOF_targets.y, final_prediction))\n",
    "\n",
    "\n",
    "# Optimize ensemble weights on held out fold\n",
    "def optimize(preds_X_test) :\n",
    "    scores = []\n",
    "    weights = []\n",
    "    for i in range(100):\n",
    "        # Choose many random starting weights\n",
    "        starting_values = np.random.uniform(size = len(preds_X_test))\n",
    "\n",
    "        # Our weights are bound between 0 and 1\n",
    "        bounds = [(0, 1)] * len(preds_X_test)\n",
    "\n",
    "        res = minimize(\n",
    "            target_func, \n",
    "            starting_values, \n",
    "            method = \"SLSQP\", \n",
    "            bounds = bounds, \n",
    "            options = {\"maxiter\" : 10000})\n",
    "\n",
    "        scores.append(res[\"fun\"])\n",
    "        weights.append(res[\"x\"])\n",
    "\n",
    "    bestSC = -np.min(scores)\n",
    "    bestWght = weights[np.argmin(scores)]\n",
    "\n",
    "    print(\"\\n Ensemble Score: {}\".format(bestSC))\n",
    "    print(\"\\n Best Weights: {}\".format(bestWght))\n",
    "\n",
    "    return(bestSC, bestWght)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Script</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>91.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>91.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>91.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>90.110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      y\n",
       "0   1 99.150\n",
       "1   2 91.980\n",
       "2   3 91.520\n",
       "3   4 91.570\n",
       "4   5 90.110"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "OOF_targets = pd.read_csv(\"clean_data/OOF_targets.csv\")\n",
    "init_test = pd.read_csv(\"raw_data/test.csv\")\n",
    "test_ids = init_test.ID.values\n",
    "\n",
    "display(OOF_targets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et_dc15</th>\n",
       "      <th>et_dc2_</th>\n",
       "      <th>et_dc3_</th>\n",
       "      <th>et_dc4_</th>\n",
       "      <th>et_dc5_</th>\n",
       "      <th>et_dc6_</th>\n",
       "      <th>et_dc7_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.818</td>\n",
       "      <td>93.930</td>\n",
       "      <td>94.019</td>\n",
       "      <td>94.160</td>\n",
       "      <td>94.039</td>\n",
       "      <td>94.100</td>\n",
       "      <td>94.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.741</td>\n",
       "      <td>93.982</td>\n",
       "      <td>93.982</td>\n",
       "      <td>93.949</td>\n",
       "      <td>93.986</td>\n",
       "      <td>93.964</td>\n",
       "      <td>94.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.208</td>\n",
       "      <td>93.446</td>\n",
       "      <td>93.706</td>\n",
       "      <td>93.492</td>\n",
       "      <td>93.522</td>\n",
       "      <td>93.697</td>\n",
       "      <td>93.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.758</td>\n",
       "      <td>94.222</td>\n",
       "      <td>93.978</td>\n",
       "      <td>94.369</td>\n",
       "      <td>94.215</td>\n",
       "      <td>94.246</td>\n",
       "      <td>94.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.321</td>\n",
       "      <td>94.412</td>\n",
       "      <td>93.944</td>\n",
       "      <td>94.455</td>\n",
       "      <td>94.504</td>\n",
       "      <td>94.523</td>\n",
       "      <td>94.437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   et_dc15  et_dc2_  et_dc3_  et_dc4_  et_dc5_  et_dc6_  et_dc7_\n",
       "0   93.818   93.930   94.019   94.160   94.039   94.100   94.131\n",
       "1   93.741   93.982   93.982   93.949   93.986   93.964   94.041\n",
       "2   93.208   93.446   93.706   93.492   93.522   93.697   93.512\n",
       "3   93.758   94.222   93.978   94.369   94.215   94.246   94.141\n",
       "4   94.321   94.412   93.944   94.455   94.504   94.523   94.437"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>et_dc15</th>\n",
       "      <th>et_dc2_</th>\n",
       "      <th>et_dc3_</th>\n",
       "      <th>et_dc4_</th>\n",
       "      <th>et_dc5_</th>\n",
       "      <th>et_dc6_</th>\n",
       "      <th>et_dc7_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.668</td>\n",
       "      <td>78.365</td>\n",
       "      <td>77.753</td>\n",
       "      <td>78.544</td>\n",
       "      <td>78.549</td>\n",
       "      <td>79.078</td>\n",
       "      <td>78.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.689</td>\n",
       "      <td>93.904</td>\n",
       "      <td>93.871</td>\n",
       "      <td>93.892</td>\n",
       "      <td>93.962</td>\n",
       "      <td>94.017</td>\n",
       "      <td>93.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.303</td>\n",
       "      <td>77.510</td>\n",
       "      <td>77.420</td>\n",
       "      <td>77.199</td>\n",
       "      <td>77.466</td>\n",
       "      <td>77.166</td>\n",
       "      <td>77.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.276</td>\n",
       "      <td>78.111</td>\n",
       "      <td>77.434</td>\n",
       "      <td>78.561</td>\n",
       "      <td>78.164</td>\n",
       "      <td>78.466</td>\n",
       "      <td>78.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.993</td>\n",
       "      <td>112.932</td>\n",
       "      <td>112.707</td>\n",
       "      <td>113.328</td>\n",
       "      <td>112.907</td>\n",
       "      <td>113.103</td>\n",
       "      <td>113.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   et_dc15  et_dc2_  et_dc3_  et_dc4_  et_dc5_  et_dc6_  et_dc7_\n",
       "0   78.668   78.365   77.753   78.544   78.549   79.078   78.543\n",
       "1   93.689   93.904   93.871   93.892   93.962   94.017   93.963\n",
       "2   77.303   77.510   77.420   77.199   77.466   77.166   77.539\n",
       "3   78.276   78.111   77.434   78.561   78.164   78.466   78.226\n",
       "4  112.993  112.932  112.707  113.328  112.907  113.103  113.004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Level 2 inputs\n",
    "level_one_OOF, level_one_test = get_level_one_outputs(OOF_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global OOF r2_score for et_dc15 : 0.565423151536\n",
      "Global OOF r2_score for et_dc2_ : 0.564604887927\n",
      "Global OOF r2_score for et_dc3_ : 0.566072957735\n",
      "Global OOF r2_score for et_dc4_ : 0.563813793244\n",
      "Global OOF r2_score for et_dc5_ : 0.564090667366\n",
      "Global OOF r2_score for et_dc6_ : 0.56416472274\n",
      "Global OOF r2_score for et_dc7_ : 0.564040091236\n"
     ]
    }
   ],
   "source": [
    "# Get error of each OOF column\n",
    "preds_X_test = []\n",
    "for col in level_one_OOF.columns :\n",
    "    cv_score = r2_score(OOF_targets.y, level_one_OOF[col])\n",
    "    print(\"Global OOF r2_score for \" + col + \" : \" + str(cv_score))\n",
    "\n",
    "    preds_X_test.append(level_one_OOF[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ensemble Score: 0.5671744331684818\n",
      "\n",
      " Best Weights: [  4.81152288e-01   7.16523087e-17   5.20450577e-01   2.39230851e-18\n",
      "   4.48331193e-18   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Optimize weights\n",
    "bestSC, bestWght = optimize(preds_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare submission using optimal weights\n",
    "preds = 0\n",
    "for i in range(0, len(bestWght)) :\n",
    "    preds = preds + (bestWght[i] * level_one_test[[i]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       78.318\n",
       "1       93.934\n",
       "2       77.488\n",
       "3       77.963\n",
       "4      113.025\n",
       "5       93.491\n",
       "6      112.674\n",
       "7       93.892\n",
       "8      116.375\n",
       "9       94.237\n",
       "10     115.576\n",
       "11     110.244\n",
       "12      97.439\n",
       "13      94.232\n",
       "14     103.920\n",
       "15      99.346\n",
       "16     117.134\n",
       "17      98.485\n",
       "18      94.867\n",
       "19      95.807\n",
       "20      98.485\n",
       "21      98.485\n",
       "22      94.553\n",
       "23      95.980\n",
       "24      93.894\n",
       "25     118.407\n",
       "26     102.807\n",
       "27     103.584\n",
       "28      94.089\n",
       "29      77.425\n",
       "         ...  \n",
       "4179   111.291\n",
       "4180   102.958\n",
       "4181    93.298\n",
       "4182    93.417\n",
       "4183   102.759\n",
       "4184   110.394\n",
       "4185    92.955\n",
       "4186    93.354\n",
       "4187   111.953\n",
       "4188   110.600\n",
       "4189    93.121\n",
       "4190   113.596\n",
       "4191    92.696\n",
       "4192   103.577\n",
       "4193    93.181\n",
       "4194   111.413\n",
       "4195    93.395\n",
       "4196   103.769\n",
       "4197   102.370\n",
       "4198   112.395\n",
       "4199    92.956\n",
       "4200    92.794\n",
       "4201    93.271\n",
       "4202   111.698\n",
       "4203   110.803\n",
       "4204   103.522\n",
       "4205    95.201\n",
       "4206    93.109\n",
       "4207   110.576\n",
       "4208    92.756\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(preds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "file_name = \"ens_preds/avg_\" + str(level_one_OOF.shape[1]) + \".csv\"\n",
    "pd.DataFrame({\"ID\": init_test.ID.values, \"y\": pd.DataFrame(preds)[0]}).to_csv(file_name, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''# Get validation set data\n",
    "la_preds_X_test = np.array(pd.read_csv(\"preds/la_preds_X_test.csv\", header = None))\n",
    "et_preds_X_test = np.array(pd.read_csv(\"preds/et_preds_X_test.csv\", header = None))\n",
    "xg_preds_X_test = np.array(pd.read_csv(\"preds/xg_preds_X_test.csv\", header = None))\n",
    "\n",
    "# Get test set data\n",
    "la_preds_test = np.array(pd.read_csv(\"preds/la_preds_test.csv\"))\n",
    "et_preds_test = np.array(pd.read_csv(\"preds/et_preds_test.csv\"))\n",
    "xg_preds_test = np.array(pd.read_csv(\"preds/xg_preds_test.csv\"))\n",
    "\n",
    "preds_X_test = []\n",
    "preds_X_test.append(la_preds_X_test[:, 0])\n",
    "preds_X_test.append(et_preds_X_test[:, 0])\n",
    "preds_X_test.append(xg_preds_X_test[:, 0])\n",
    "\n",
    "preds_test = []\n",
    "preds_test.append(la_preds_test[:, 1])\n",
    "preds_test.append(et_preds_test[:, 1])\n",
    "preds_test.append(xg_preds_test[:, 1])\n",
    "\n",
    "names = []\n",
    "names.append(\"la\")\n",
    "names.append(\"et\")\n",
    "names.append(\"xg\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''# Scores of single models on validation set\n",
    "print(\"la on held out fold : \" + str(r2_score(X_test_y, la_preds_X_test)))\n",
    "print(\"et on held out fold : \" + str(r2_score(X_test_y, et_preds_X_test)))\n",
    "print(\"xg on held out fold : \" + str(r2_score(X_test_y, xg_preds_X_test)))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''# Optimize weights\n",
    "bestSC, bestWght, names = optimize(preds_X_test, names)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''# Prepare submission using optimal weights\n",
    "preds = 0\n",
    "for i in range(0, len(bestWght)) :\n",
    "    (bestWght[i] * preds_test[i])\n",
    "    preds += (bestWght[i] * preds_test[i])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''# Save predictions\n",
    "pd.DataFrame({\"ID\": test_ids[0], \"y\": preds}).to_csv(\"preds/blend.csv\", index = False)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
